{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b238a1e-5aec-466f-9f08-707c4581907d",
   "metadata": {},
   "source": [
    "# __First contact__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f02ed48-20b4-4358-8b43-b37d6e559102",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e676d2b5-b4b9-407a-a8c3-d0767b8a7429",
   "metadata": {},
   "source": [
    "!pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6a8b776-2df4-4d6e-9dbe-e7bd2f57b939",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35ce611c-d7b8-4a80-a4fd-a4c65d8eef69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab7c7d83-f6d4-499a-9a56-e3d275341b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4787d54f-b84b-4cf4-9cc9-66052e410809",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject list at 0x7f97fc75d770> JSON: {\n",
       "  \"data\": [\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"ada\",\n",
       "      \"max_replicas\": null,\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true,\n",
       "      \"ready_replicas\": null,\n",
       "      \"replicas\": null\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"babbage\",\n",
       "      \"max_replicas\": null,\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": false,\n",
       "      \"ready_replicas\": null,\n",
       "      \"replicas\": null\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"curie\",\n",
       "      \"max_replicas\": null,\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true,\n",
       "      \"ready_replicas\": null,\n",
       "      \"replicas\": null\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"curie-instruct-beta\",\n",
       "      \"max_replicas\": null,\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": false,\n",
       "      \"ready_replicas\": null,\n",
       "      \"replicas\": null\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"davinci\",\n",
       "      \"max_replicas\": null,\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true,\n",
       "      \"ready_replicas\": null,\n",
       "      \"replicas\": null\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"davinci-instruct-beta\",\n",
       "      \"max_replicas\": null,\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true,\n",
       "      \"ready_replicas\": null,\n",
       "      \"replicas\": null\n",
       "    },\n",
       "    {\n",
       "      \"created\": null,\n",
       "      \"id\": \"davinci-instruct-beta-v3\",\n",
       "      \"max_replicas\": null,\n",
       "      \"object\": \"engine\",\n",
       "      \"owner\": \"openai\",\n",
       "      \"permissions\": null,\n",
       "      \"ready\": true,\n",
       "      \"ready_replicas\": null,\n",
       "      \"replicas\": null\n",
       "    }\n",
       "  ],\n",
       "  \"object\": \"list\"\n",
       "}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.Engine.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abaa5d5a-ecb5-4993-9348-6010e03bdd54",
   "metadata": {},
   "source": [
    "# __Fine Tuning__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0e738a-82f6-4aa7-8b09-d9e3dc0713fe",
   "metadata": {},
   "source": [
    "Your data must be a JSONL document, where each line is a prompt-completion pair corresponding to a training example. \n",
    "Use the data_cleaning notebook to get this format - notebook puts whitespace in front and END at the end of every completion as required by openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "169fce19-89d7-4713-aa6d-556de875e1f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\"prompt\": \"<prompt text>\", \"completion\": \" <ideal generated text> END\"}\n",
    "{\"prompt\": \"<prompt text>\", \"completion\": \"<ideal generated text>\"}\n",
    "{\"prompt\": \"<prompt text>\", \"completion\": \"<ideal generated text>\"}\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eed03dd-f3fc-43bf-80c1-a3384d2c43b7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## __CLI data preparation tool__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "86012949-73c3-4d40-b86c-8dfdbe7184c9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing...\n",
      "\n",
      "- Your file contains 58047 prompt-completion pairs\n",
      "\n",
      "No remediations found.\n",
      "\n",
      "You can use your file for fine-tuning:\n",
      "> openai api fine_tunes.create -t \"lifestyle.json\" --batch_size 1\n",
      "\n",
      "After youâ€™ve fine-tuned a model, remember that your prompt has to end with the indicator string `` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\". END\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 13.33 hours to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
     ]
    }
   ],
   "source": [
    "# tool which validates, gives suggestions and reformats your data:\n",
    "!openai tools fine_tunes.prepare_data -f lifestyle.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60ff456-f5a6-467a-b7fb-334f98532ea4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## __actual fine tuning for console__\n",
    "\n",
    "__Every fine-tuning job starts from a base model, which defaults to curie. The choice of model influences both the performance of the model and the cost of running your fine-tuned model. Your model can be one of: ada, babbage, or curie.__</br>\n",
    "\n",
    "***just for console***\n",
    "\n",
    "thus __add key to your zshrc:__ </br>\n",
    "<font color='green'>export OPENAI_API_KEY=\"OPENAI_API_KEY\"</font>\n",
    "\n",
    "If the event stream is __interrupted for any reason, you can resume__ it by running:</br>\n",
    "<font color='green'>openai api fine_tunes.follow -i YOUR_FINE_TUNE_JOB_ID</font>\n",
    "\n",
    "__feed the prepared file to a model__ (here it's babbage) - takes some minutes </br>\n",
    "<font color='green'>openai api fine_tunes.create -t babyfood_new.json -m babbage</font>\n",
    "\n",
    "__In addition to creating a fine-tune job, you can also list existing jobs, retrieve the status of a job, or cancel a job.__</br>\n",
    "List all created fine-tunes </br>\n",
    "<font color='green'>openai api fine_tunes.list</font>\n",
    "\n",
    "\n",
    "__Retrieve the state of a fine-tune.__</br>\n",
    "The resulting object includes: job status (which can be one of pending, running, succeeded, or failed) and other information</br>\n",
    "<font color='green'>openai api fine_tunes.get -i YOUR_FINE_TUNE_JOB_ID</font>\n",
    "\n",
    "__Cancel a job__</br>\n",
    "<font color='green'>openai api fine_tunes.cancel -i YOUR_FINE_TUNE_JOB_ID</font>\n",
    "\n",
    "__Analyzing your fine-tuned model__</br>\n",
    "This results file ID will be listed when you retrieve a fine-tune, and also when you look at the events on a fine-tune.</br>\n",
    "<font color='green'>openai api fine_tunes.results -i YOUR_FINE_TUNE_JOB_ID</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d8e84a-a8ba-4a8a-9df8-be06dfcb959b",
   "metadata": {},
   "source": [
    "## __Hyperparameters__\n",
    "\n",
    "The only required parameter is the training file.</br>\n",
    "tweaking the hyperparameters for fine-tuning can lead to higher quality output. \n",
    "\n",
    "__model:__ name of the base model to fine-tune. You can select one of \"ada\", \"babbage\", or \"curie\".</br>\n",
    "\n",
    "__n_epochs__ - default 4. An epoch refers to one full cycle through the training dataset.</br>\n",
    "\n",
    "__batch_size__ - defaults to ~0.2% of the number of examples in the training set, capped at 8. The batch size is the number of training examples used to train a single forward and backward pass. When use_packing is true, the batch size becomes the number of 2048-token contexts instead of the number of raw examples. In general, we've found that larger batch sizes tend to work better for larger datasets.</br>\n",
    "    \n",
    "__learning_rate_multiplier__ - defaults to 0.05. The fine-tuning learning rate is the original learning rate used for pretraining multiplied by this multiplier. We recommend experimenting with values in the range 0.02 to 0.2 to see what produces the best results. Empirically, we've found that larger learning rates often perform better with larger batch sizes.</br>\n",
    "    \n",
    "__use_packing / no_packing:__ defaults to use_packing for datasets with at least 500k tokens. On classification tasks and small datasets, we recommend setting no_packing, else use_packing. When using packing, we pack as many prompt-completion pairs as possible into each training example. This greatly increases the speed of a fine-tuning job.</br>\n",
    "\n",
    "__compute_classification_metrics__ - defaults to False. If True, for fine-tuning for classification tasks, computes classification-specific metrics (accuracy, F-1 score, etc) on the validation set at the end of every epoch.</br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e217221-725b-495f-8c52-00deeee8def9",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai api fine_tunes.create \\\n",
    "    -t file-JD89ePi5KMsB3Tayeli5ovfW \\\n",
    "    -m ada \\\n",
    "    --use_packing \\\n",
    "    --n_epochs 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f17db0b-3993-4f08-8277-252a31f7c1fd",
   "metadata": {},
   "source": [
    "## __Fine Tune details__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bf6c665c-ba9d-4601-8f1f-451f1a985b0b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject list at 0x7f47e25e5e50> JSON: {\n",
       "  \"data\": [\n",
       "    {\n",
       "      \"created_at\": 1638189561,\n",
       "      \"fine_tuned_model\": \"babbage:ft-user-r4iwcdpoxftbglfzc8c2mfn7-2021-11-29-13-04-27\",\n",
       "      \"hyperparams\": {\n",
       "        \"batch_size\": 1,\n",
       "        \"learning_rate_multiplier\": 0.05,\n",
       "        \"n_epochs\": 4,\n",
       "        \"prompt_loss_weight\": 0.1,\n",
       "        \"use_packing\": true\n",
       "      },\n",
       "      \"id\": \"ft-IVKLoqPihI5FwLjTSfFXExjp\",\n",
       "      \"model\": \"babbage\",\n",
       "      \"object\": \"fine-tune\",\n",
       "      \"organization_id\": \"org-9ghUN8S9cCwE0yzpHXHDbEGa\",\n",
       "      \"result_files\": [\n",
       "        {\n",
       "          \"bytes\": 154961,\n",
       "          \"created_at\": 1638191070,\n",
       "          \"filename\": \"compiled_results.csv\",\n",
       "          \"id\": \"file-SCYKCs0T31IEupjlCEotC6CP\",\n",
       "          \"object\": \"file\",\n",
       "          \"purpose\": \"fine-tune-results\",\n",
       "          \"status\": \"processed\",\n",
       "          \"status_details\": null\n",
       "        }\n",
       "      ],\n",
       "      \"status\": \"succeeded\",\n",
       "      \"training_files\": [\n",
       "        {\n",
       "          \"bytes\": 8353221,\n",
       "          \"created_at\": 1638189560,\n",
       "          \"filename\": \"babyfood_new.json\",\n",
       "          \"id\": \"file-oKSSO8yDnWJxI1b1mfAXjQly\",\n",
       "          \"object\": \"file\",\n",
       "          \"purpose\": \"fine-tune\",\n",
       "          \"status\": \"processed\",\n",
       "          \"status_details\": null\n",
       "        }\n",
       "      ],\n",
       "      \"updated_at\": 1638191073,\n",
       "      \"validation_files\": []\n",
       "    }\n",
       "  ],\n",
       "  \"object\": \"list\"\n",
       "}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# jobs\n",
    "openai.FineTune.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "46d43169-1752-4fe3-b31c-21dd64051799",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FineTune fine-tune id=ft-IVKLoqPihI5FwLjTSfFXExjp at 0x7f97fc223b30> JSON: {\n",
       "  \"created_at\": 1638189561,\n",
       "  \"events\": [\n",
       "    {\n",
       "      \"created_at\": 1638189561,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Created fine-tune: ft-IVKLoqPihI5FwLjTSfFXExjp\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1638189576,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune enqueued. Queue number: 0\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1638189580,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune started\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1638189965,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Completed epoch 1/4\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1638190319,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Completed epoch 2/4\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1638190672,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Completed epoch 3/4\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1638191025,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Completed epoch 4/4\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1638191069,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Uploaded model: babbage:ft-user-r4iwcdpoxftbglfzc8c2mfn7-2021-11-29-13-04-27\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1638191072,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Uploaded result file: file-SCYKCs0T31IEupjlCEotC6CP\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1638191072,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune succeeded\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    }\n",
       "  ],\n",
       "  \"fine_tuned_model\": \"babbage:ft-user-r4iwcdpoxftbglfzc8c2mfn7-2021-11-29-13-04-27\",\n",
       "  \"hyperparams\": {\n",
       "    \"batch_size\": 1,\n",
       "    \"learning_rate_multiplier\": 0.05,\n",
       "    \"n_epochs\": 4,\n",
       "    \"prompt_loss_weight\": 0.1,\n",
       "    \"use_packing\": true\n",
       "  },\n",
       "  \"id\": \"ft-IVKLoqPihI5FwLjTSfFXExjp\",\n",
       "  \"model\": \"babbage\",\n",
       "  \"object\": \"fine-tune\",\n",
       "  \"organization_id\": \"org-9ghUN8S9cCwE0yzpHXHDbEGa\",\n",
       "  \"result_files\": [\n",
       "    {\n",
       "      \"bytes\": 154961,\n",
       "      \"created_at\": 1638191070,\n",
       "      \"filename\": \"compiled_results.csv\",\n",
       "      \"id\": \"file-SCYKCs0T31IEupjlCEotC6CP\",\n",
       "      \"object\": \"file\",\n",
       "      \"purpose\": \"fine-tune-results\",\n",
       "      \"status\": \"processed\",\n",
       "      \"status_details\": null\n",
       "    }\n",
       "  ],\n",
       "  \"status\": \"succeeded\",\n",
       "  \"training_files\": [\n",
       "    {\n",
       "      \"bytes\": 8353221,\n",
       "      \"created_at\": 1638189560,\n",
       "      \"filename\": \"babyfood_new.json\",\n",
       "      \"id\": \"file-oKSSO8yDnWJxI1b1mfAXjQly\",\n",
       "      \"object\": \"file\",\n",
       "      \"purpose\": \"fine-tune\",\n",
       "      \"status\": \"processed\",\n",
       "      \"status_details\": null\n",
       "    }\n",
       "  ],\n",
       "  \"updated_at\": 1638191073,\n",
       "  \"validation_files\": []\n",
       "}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# infos\n",
    "openai.FineTune.retrieve(id=\"ft-IVKLoqPihI5FwLjTSfFXExjp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56141550-ec24-49ed-9569-32342650f644",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "Cannot cancel a job ft-IVKLoqPihI5FwLjTSfFXExjp that already has status \"succeeded\".",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1784/657228715.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Immediately cancel a fine-tune job.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mopenai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFineTune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcancel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ft-IVKLoqPihI5FwLjTSfFXExjp\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/baby/lib/python3.8/site-packages/openai/api_resources/fine_tune.py\u001b[0m in \u001b[0;36mcancel\u001b[0;34m(cls, id, api_key, request_id, **params)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"%s/%s/cancel\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0minstance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/baby/lib/python3.8/site-packages/openai/openai_object.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, stream, plain_old_data, request_id)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0morganization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morganization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         )\n\u001b[0;32m--> 170\u001b[0;31m         response, stream, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         )\n",
      "\u001b[0;32m~/.pyenv/versions/baby/lib/python3.8/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mrequest_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         )\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/baby/lib/python3.8/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             return (\n\u001b[0;32m--> 292\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    293\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m                 ),\n",
      "\u001b[0;32m~/.pyenv/versions/baby/lib/python3.8/site-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"error\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             raise self.handle_error_response(\n\u001b[0m\u001b[1;32m    319\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m             )\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: Cannot cancel a job ft-IVKLoqPihI5FwLjTSfFXExjp that already has status \"succeeded\"."
     ]
    }
   ],
   "source": [
    "# Immediately cancel a fine-tune job.\n",
    "openai.FineTune.cancel(id=\"ft-IVKLoqPihI5FwLjTSfFXExjp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bb8c2374-e899-4c25-a8a1-41e687c46f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "FINE_TUNED_MODEL = \"babbage:ft-user-r4iwcdpoxftbglfzc8c2mfn7-2021-11-29-13-04-27\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9f3b3e69-0bd9-4a09-8af1-f1dd79daeb01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Model model id=babbage:ft-user-r4iwcdpoxftbglfzc8c2mfn7-2021-11-29-13-04-27 at 0x7f97fffcdcc0> JSON: {\n",
       "  \"deleted\": true,\n",
       "  \"id\": \"babbage:ft-user-r4iwcdpoxftbglfzc8c2mfn7-2021-11-29-13-04-27\",\n",
       "  \"object\": \"model\"\n",
       "}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete a fine tuned model\n",
    "openai.Model.delete(FINE_TUNED_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5742d0d1-61a7-497e-8f3e-64e06ec95daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get fine-grained status updates for a fine-tune job.\n",
    "openai.FineTune.list_events(id=\"ftjb-AF1WoRqd3aJAHsqc9NY7iL8F\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cc31fd-61f8-4354-8806-856075fae659",
   "metadata": {},
   "source": [
    "## __Try tuned model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e8617e6-b30c-40d7-92a5-aa7c3f307457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR_FINE_TUNE_JOB_ID\n",
    "FINE_TUNED_MODEL = \"babbage:ft-user-r4iwcdpoxftbglfzc8c2mfn7-2021-11-29-13-04-27\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03172079-cd35-4456-886c-c234d8fa2688",
   "metadata": {},
   "source": [
    "Note that no engine is specified on these requests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab7d7d0-a0d1-44db-b22a-2ba14d973473",
   "metadata": {},
   "source": [
    "## __create a prompt and get a completion__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c22f65eb-7381-4805-bc5f-bbf375b40a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt4 = '''\n",
    "Rewrite the following rap verse about technology. Follow the rhyming pattern. ->:\n",
    "\n",
    "Hold the cold one like he hold a old gun\\n\n",
    "Like he hold the microphone and stole the show for fun\\n\n",
    "Or a foe for ransom, flows is handsome\\n\n",
    "O's in tandem, anthem, random, tantrum\\n\n",
    "Phantom of the Grand Ole Opry ask the dumb hottie\\n\n",
    "Masked pump shotty, somebody stop me\\n\n",
    "Hardly come sloppy on a retarded hard copy\\n\n",
    "After rockin' parties he departed in a jalopy\\n END\n",
    "\n",
    "Rewrite the following rap verse about technology. Follow the rhyming pattern. ->:'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65eb0f7c-5d89-448a-b07d-248df67233ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_response4 = openai.Completion.create(\n",
    "        model=FINE_TUNED_MODEL,\n",
    "        prompt=prompt4,\n",
    "        max_tokens= 50,\n",
    "        temperature=0.84,\n",
    "        presence_penalty=1,\n",
    "        frequency_penalty=0,\n",
    "        n=1,\n",
    "        stop=[\" END\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51c9a83a-3500-418b-a8b4-3e116d3767eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " that thing that makes the world go round is technology ### i think was trying to make a broader point about how much things have changed since the th ### opening statement looks like it will be an interesting yearhope you can stay with me ### watch president\n"
     ]
    }
   ],
   "source": [
    "print(fine_response4[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff349f5b-0475-452b-94aa-63931339b4e8",
   "metadata": {},
   "source": [
    "## __Upload a file__ \n",
    "...that contains document(s) to be used across various endpoints/features.</br>\n",
    "The ID of an uploaded file that contains documents to search over. Up to 1 GB.</br>\n",
    "You should specify either documents or a file, but not both.</br>\n",
    "If __purpose__ is set to \"fine-tune\", each line is a JSON record with \"prompt\" and \"completion\" </br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "59b683a2-a1c5-4ec9-8002-2cc0435b46bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<File file id=file-wBtY1KEgkaM646pRCxniyPEI at 0x7f97fc290e00> JSON: {\n",
       "  \"bytes\": 8411268,\n",
       "  \"created_at\": 1638284301,\n",
       "  \"filename\": \"lifestyle.json\",\n",
       "  \"id\": \"file-wBtY1KEgkaM646pRCxniyPEI\",\n",
       "  \"object\": \"file\",\n",
       "  \"purpose\": \"fine-tune\",\n",
       "  \"status\": \"uploaded\",\n",
       "  \"status_details\": null\n",
       "}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.File.create(\n",
    "  file=open(\"lifestyle.json\"),\n",
    "  purpose='fine-tune')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886e1bf6-0921-4437-97d4-52599bae4d04",
   "metadata": {},
   "source": [
    "## __file handeling__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fce590c8-175c-43ae-bb6c-2294b3a31ce3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject list at 0x7f97fc22ccc0> JSON: {\n",
       "  \"data\": [\n",
       "    {\n",
       "      \"bytes\": 8411268,\n",
       "      \"created_at\": 1638284301,\n",
       "      \"filename\": \"lifestyle.json\",\n",
       "      \"id\": \"file-wBtY1KEgkaM646pRCxniyPEI\",\n",
       "      \"object\": \"file\",\n",
       "      \"purpose\": \"fine-tune\",\n",
       "      \"status\": \"uploaded\",\n",
       "      \"status_details\": null\n",
       "    }\n",
       "  ],\n",
       "  \"object\": \"list\"\n",
       "}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list uploaded files\n",
    "openai.File.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bd6499ff-95c8-43a0-96dd-63c3ca187bf0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# delete a file - does not work\n",
    "openai.File(\"file-oKSSO8yDnWJxI1b1mfAXjQly\").delete()\n",
    "\n",
    "# shell works \n",
    "!curl https://api.openai.com/v1/files/file-SCYKCs0T31IEupjlCEotC6CP -X DELETE -H 'Authorization: BEARER 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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3e02ca-c0c8-411c-b4f3-acd625e460a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve file\n",
    "openai.File.retrieve(\"file-XjGxS3KTG0uNmNOK362iJua3\")\n",
    "\n",
    "# retrieve file content\n",
    "content = openai.File.download(\"file-XjGxS3KTG0uNmNOK362iJua3\")\n",
    "\n",
    "# fine tune with a uploaded file\n",
    "openai.FineTune.create(training_file=\"file-XGinujblHPwGLSztz8cPS8XY\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
